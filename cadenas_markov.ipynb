{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pressing-munich",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Simulación y aplicaciones en ciencias sociales y experimentales\n",
    "</h3>\n",
    "<h3 style=\"text-align: center;\"> Tema 3. Modelos aleatorios </h3>\n",
    "<h3 style=\"text-align: center;\"> Cadenas de Markov</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b132e",
   "metadata": {},
   "source": [
    "Una cadena de Markov es un tipo de proceso estocástico. Así, antes de comenzar con la modelización, introduzcamos estos conceptos generales previos:\n",
    "\n",
    "Un **proceso estocástico** es un conjunto de variables aleatorias $\\{X_t\\}_{t \\in T}$, donde $T$ suele representar el tiempo. En su versión discreta $T$ es un subconjunto de los números naturales. La version aleatoria de los modelos SIR de difusión de una enfermedad son ejemplos de procesos estocásticos donde $X_t$ puede ser el número de infectados en cada instante del tiempo. \n",
    "\n",
    "Los posibles valores $x_t$ de un proceso estocástico $X_t$ se les llama **estados**, y cuando los estados se encuentran en un espacio discreto al proceso estocástico se le denomina **cadena**. Generalmente, los estados $x_t$ de un proceso estocástico dependen de los estados en fases anteriores del tiempo. Cuando ese estado depende exclusivamente del estado en el instante anterior se dice que estamos ante una **cadena de Markov**. Escrito en tiempo discreto una cadena de Markov satisface la siguiente propiedad: \n",
    "\n",
    " $$P[X_{t+1}=x_{t+1}/X_{t}=x_{t},X_{t-1}=x_{t-1},...,X_0=x_0] = P[X_{t+1}=x_{t+1}/X_{t}=x_{t}].$$\n",
    "\n",
    "Escrito en tiempo continuo, la propiedad sería que dados los instantes $t_1<t_2<...<t_{k}$ pertenecientes a $T$, se verifica: \n",
    "\n",
    "$$P[X(t_k)=i_k/X(t_{k-1})=i_{k-1},..., X(t_1)=i_1] = P[X(t_k)=i_k/X(t_{k-1})=i_{k-1}],$$\n",
    "\n",
    "para todo $i_1$, $i_2$,..., $i_k$ estados. \n",
    " \n",
    "A modo de ejemplo, ¿es el modelo SIR estocástico una cadena de Markov?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442859f-1623-42c3-bffe-aff36760e172",
   "metadata": {},
   "source": [
    "### Cadenas de Markov discretas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e9de1-45af-4bb7-805a-c708c712f6c4",
   "metadata": {},
   "source": [
    "En una cadena de Markov discretas, se define la **probabilidad conditional $p_{ij}(n)$** a la probabilidad de que el proceso esté en el estado $i$ en el instante $n$ y en el estado $j$ en el instante $n+1$. Esto es: \n",
    "$$p_{ij}(n) = P[X_{n+1}=j/X_{n}=i].$$\n",
    "Se dice que una cadena de Markov es **homogénea** cuando las probabilidades de pasar de un estado a otro son independientes del tiempo, esto es $p_{ij}(n) = p_{ij}$, $\\forall i,j$ estados cualesquiera. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92896e99-8526-4714-b172-e14f2463aeaa",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec6d30",
   "metadata": {},
   "source": [
    "La predicción del tiempo pudiera modelarse a través de una cadena de Markov. Supóngase que hay tres tipos de estados: soleado (S), nublado (C) y lluvioso (R). El tiempo se observa cada día. La probabilidad de que haya un día soleado despues de otro día soleado es 0.8 y de que sea nublado 0.15. La probabilidad de que haya un día nublado después de otro nublado es 0.2 y soleado 0.7. La probabilidad de que haya un día lluvioso después de otro lluvioso es 0.2, y que sea soleado 0.5.  \n",
    "\n",
    "**a)** Supóngase que hoy es un día nublado. Indicar la probabilidad a largo plazo de que el día sea soleado, nublado o lluvioso; **b)** Asumir una predicción cualquiera para el día de hoy y calcular de nuevo la probabilidad a largo plazo de que el día sea soleado, nublado o lluvioso. Indicar si esta probabilidad depende del pronóstico actual. **c)** Si el pronóstico del tiempo indica que hoy hay $\\alpha_1$% de posibilidades de que sea soleado, $\\alpha_2$% de posibilidades de que sea nublado y $\\alpha_3$% de posibilidades de que sea lluvioso, indicar la expresión que determina el pronóstico del tiempo al día siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5f0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b901c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad a largo plazo con día inicial nublado:\n",
      "Soleado: 0.7625, Nublado: 0.1688, Lluvioso: 0.0688\n",
      "\n",
      "Probabilidad a largo plazo con distribución inicial general:\n",
      "Soleado: 0.7625, Nublado: 0.1688, Lluvioso: 0.0688\n",
      "\n",
      "Pronóstico para mañana dado el pronóstico de hoy (50% Soleado, 30% Nublado, 20% Lluvioso):\n",
      "Soleado: 0.7100, Nublado: 0.1950, Lluvioso: 0.0950\n"
     ]
    }
   ],
   "source": [
    "P = np.array([\n",
    "    [0.8, 0.15, 0.05],\n",
    "    [0.7, 0.2, 0.1],\n",
    "    [0.5, 0.3, 0.2]\n",
    "])\n",
    "\n",
    "# Paso 1: Calcular la probabilidad a largo plazo (Ejercicio a y b)\n",
    "\n",
    "# Definimos una función para calcular la distribución estacionaria o límite\n",
    "def stationary_distribution(P, pi_0, tolerance=1e-8, max_iterations=1000):\n",
    "    pi = pi_0.copy()\n",
    "    for _ in range(max_iterations):\n",
    "        pi_next = pi @ P\n",
    "        if np.allclose(pi_next, pi, atol=tolerance):\n",
    "            break\n",
    "        pi = pi_next\n",
    "    return pi\n",
    "\n",
    "# Distribución inicial para \"día nublado\" (Ejercicio a)\n",
    "pi_0_nublado = np.array([0, 1, 0])\n",
    "stationary_nublado = stationary_distribution(P, pi_0_nublado)\n",
    "\n",
    "# Distribución inicial general uniforme (Ejercicio b)\n",
    "pi_0_general = np.array([1/3, 1/3, 1/3])\n",
    "stationary_general = stationary_distribution(P, pi_0_general)\n",
    "\n",
    "# Imprimir los resultados de las probabilidades a largo plazo\n",
    "print(\"Probabilidad a largo plazo con día inicial nublado:\")\n",
    "print(f\"Soleado: {stationary_nublado[0]:.4f}, Nublado: {stationary_nublado[1]:.4f}, Lluvioso: {stationary_nublado[2]:.4f}\\n\")\n",
    "\n",
    "print(\"Probabilidad a largo plazo con distribución inicial general:\")\n",
    "print(f\"Soleado: {stationary_general[0]:.4f}, Nublado: {stationary_general[1]:.4f}, Lluvioso: {stationary_general[2]:.4f}\\n\")\n",
    "\n",
    "# Paso 2: Calcular el pronóstico del tiempo al día siguiente (Ejercicio c)\n",
    "\n",
    "# Definir una función para calcular el pronóstico\n",
    "def next_day_forecast(alpha, P):\n",
    "    return np.array(alpha) @ P\n",
    "\n",
    "# Pronóstico del tiempo hoy (distribución inicial)\n",
    "alpha_today = [0.5, 0.3, 0.2]  # 50% soleado, 30% nublado, 20% lluvioso\n",
    "forecast_tomorrow = next_day_forecast(alpha_today, P)\n",
    "\n",
    "# Imprimir el pronóstico para mañana\n",
    "print(\"Pronóstico para mañana dado el pronóstico de hoy (50% Soleado, 30% Nublado, 20% Lluvioso):\")\n",
    "print(f\"Soleado: {forecast_tomorrow[0]:.4f}, Nublado: {forecast_tomorrow[1]:.4f}, Lluvioso: {forecast_tomorrow[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225676ce-8564-4346-a1d5-34cbe0243eb5",
   "metadata": {},
   "source": [
    "#### Matriz de transición"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c842d05-8596-43af-99a0-452c49fa8bac",
   "metadata": {},
   "source": [
    "Una cadena de Markov homogénea puede representarse a través de la llamada **matriz de transición**, que incluye sus probabilidades estacionarias de la forma: \n",
    "\n",
    "$$ P = \\left[ \\begin{array}{cccc} p_{11} & p_{12} & \\cdots & p_{1k}\\\\ p_{21} & p_{22} & \\cdots & p_{2k} \\\\ \\cdots & \\cdots & \\cdots & \\cdots \\\\ p_{k1} & p_{k2} & \\cdots & p_{kk}\\end{array} \\right],$$\n",
    "\n",
    "donde se ha asumido un número $k$ finitos de estados. La matriz de transición verifica dos propiedades: \n",
    "- Todos los términos $p_{ij} \\geq 0$.\n",
    "- La suma de los valores de las filas es 1, esto es, $\\sum_{j=1}^k p_{ij} =1$.\n",
    "\n",
    "Una matriz que verifica estas propiedades se le denomina **matriz estocástica**. Es fácil demostrar que $\\lambda=1$ es un valor propio de una matriz estocástica y que todos los demás valores propios son menores que 1 en valor absoluto. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e256a-8fe9-44d9-8081-dfb2d12775cf",
   "metadata": {},
   "source": [
    "#### Estados transitorios de una cadena de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc9609-d59c-4b7d-8bdd-2f0297bcfc95",
   "metadata": {},
   "source": [
    "Asúmase una distribución inicial de estados $\\pi_0 = [\\pi_0^1,\\pi_0^2,...,\\pi_0^k]$, con $\\pi_0^i$ la probabilidad de que la cadena de Markov esté en el estado $i$ en $t=0$. Es sencillo demostar que la distribución de los estados en $t=1$, $\\pi_1$, es igual a: \n",
    "$$\\pi_1 = \\pi_0 P.$$\n",
    "Siguiendo el mismo procedimiento por recurrencia, tenemos que la distribución de los estados en el tiempo $n$, $\\pi_n$, es igual a:\n",
    "$$\\pi_n = \\pi_0 P^n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2608d-a42f-4776-a54a-fb005cc24e44",
   "metadata": {},
   "source": [
    "#### Distribución estacionaria y distribución límite "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40bf9f-e988-43a3-83be-bceb54d27568",
   "metadata": {},
   "source": [
    "A partir de la fomra de hallar la distribución sucesiva de estados, se plantean dos maneras de encontrar una distribución de estados que no evoluciona en el tiempo. \n",
    "\n",
    "1) Una **distribución estacionaria $z$** es aquella cumple:\n",
    "   $$zP=z.$$\n",
    "\n",
    "O sea, una distribución estacionaria es un vector propio a la izquierda con valor propio 1. \n",
    "\n",
    "2) Una **distribución límite $\\pi^*$** es la obtenida cuando $n\\rightarrow \\infty$. Esto es,\n",
    "   $$\\pi^*= \\lim_{n\\rightarrow \\infty} \\pi_n = \\pi_0 \\lim_{n\\rightarrow \\infty} P^n.$$\n",
    "\n",
    "Por tanto, para que existe la distribución límite de una cadena de Markov finita es necesario que exista $\\lim_{n\\rightarrow \\infty} P^n.$\n",
    "\n",
    "Es deseable que tanto la distribución estacionaria como la distribución límite existan y coincidan. Sin embargo, esto no es así en general. Definamos un tipo de cadena de Markov que sí lo cumple. \n",
    "\n",
    "**Definición:** Una cadena de Markov se dice **regular** si existe un $m>0$ tal que todos los componentes de $P^m$ son positivos. Dicho de otra manera, es una matriz en la que existe un momento donde es posible la transición en un solo paso a todos los estados del sistema.\n",
    "\n",
    "Ya estamos en disposición de presentar el siguiente teorema que asegura la igualdad entre la distribución estacionaria y la límite. \n",
    "\n",
    "**Teorema:** Si una cadena de Markov es regular, entonces se verifica que las distribuciones estacionarias $z$ y límite $\\pi^*$ coinciden y son únicas. Además $\\lim_{n\\rightarrow \\infty} P^n= P^*$ es una matriz con todas las filas iguales a $z$, y cada elemento $j$ de $z$ indica la probabilidad a largo plazo de que el sistema se encuentre en el estado $j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc5c38",
   "metadata": {},
   "source": [
    "### Ejercicio 1 (continuación)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c662e66",
   "metadata": {},
   "source": [
    "Verificar que la matriz de transición es regular. Comprobar que la distribución estacionaria $z$ coincide con la distribución límite $\\pi^*$ y verificar que $P^*$ es una matriz con todas las filas iguales a $z$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0014ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de transición es regular: True (m=1)\n",
      "\n",
      "Matriz límite P^*:\n",
      "[[0.7625 0.1687 0.0687]\n",
      " [0.7625 0.1688 0.0688]\n",
      " [0.7625 0.1688 0.0688]]\n",
      "\n",
      "Distribución estacionaria z:\n",
      "[0.7625 0.1687 0.0687]\n",
      "\n",
      "¿La distribución estacionaria z coincide con la propiedad zP=z?: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir la matriz de transición\n",
    "P = np.array([\n",
    "    [0.8, 0.15, 0.05],\n",
    "    [0.7, 0.2, 0.1],\n",
    "    [0.5, 0.3, 0.2]\n",
    "])\n",
    "\n",
    "# Verificar si la matriz de transición es regular\n",
    "def is_regular(P, max_power=100):\n",
    "    for m in range(1, max_power + 1):\n",
    "        P_m = np.linalg.matrix_power(P, m)\n",
    "        if np.all(P_m > 0):  # Si todos los elementos de P^m son positivos\n",
    "            return True, m\n",
    "    return False, None\n",
    "\n",
    "# Calcular la matriz P^* (límite de P^n)\n",
    "def limit_matrix(P, tolerance=1e-8, max_iterations=1000):\n",
    "    P_n = P.copy()\n",
    "    for _ in range(max_iterations):\n",
    "        P_next = P_n @ P\n",
    "        if np.allclose(P_next, P_n, atol=tolerance):\n",
    "            break\n",
    "        P_n = P_next\n",
    "    return P_n\n",
    "\n",
    "# Verificar si la matriz es regular\n",
    "is_regular_result, power = is_regular(P)\n",
    "\n",
    "# Calcular la matriz límite P^*\n",
    "P_star = limit_matrix(P)\n",
    "\n",
    "# Extraer la distribución estacionaria z\n",
    "z = P_star[0]  # Todas las filas de P^* deben ser iguales, así que tomamos la primera\n",
    "\n",
    "# Comprobar que z es un vector propio a la izquierda con valor propio 1\n",
    "is_stationary = np.allclose(z @ P, z)\n",
    "\n",
    "# Resultados\n",
    "print(f\"La matriz de transición es regular: {is_regular_result} (m={power})\")\n",
    "print(\"\\nMatriz límite P^*:\") \n",
    "print(P_star.round(4))\n",
    "print(\"\\nDistribución estacionaria z:\")\n",
    "print(z.round(4))\n",
    "print(f\"\\n¿La distribución estacionaria z coincide con la propiedad zP=z?: {is_stationary}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14088d",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- Spong, M.W. (2023). Introduction to Modeling and Simulation. A Systems Approach. Wiley.\n",
    "- Stewart, W. J. (2009). Probability, Markov Chains, Queues, and Simulation. Princenton University Press. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648e321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
